---
title:  "Chap 4. 여러 개의 평균 비교 _ 4.1 분산분석" 
excerpt: "통계학입문 수업 스터디 노트"

categories:
  - Statistics
tags:
  - [Statistics]

toc: true
toc_sticky: true
 
date: 2021-12-12
last_modified_at: 2021-12-14

---

앞 게시물에서 카이-제곱 검증으로 범주형 변수 하나의 범주간의 비율 그리고 두 개의 범주형 변수간의 연관성에 대한 검증을 하였다. Chap 4는 평균 차이의 검증을 확장하는 방법을 소개한다. 이 방법을 통해 양적 변수와 범주형 변수의 관계를 분석한다. 

## 분산분석(ANOVA)

t-검증을 사용하여 독립된 두 집단 간(범주형)의 양적 변수의 평균을 비교하였다. 하지만 세 집단 이상을 비교할 때 분산분석을 이용하면 된다. 분산분석은 집단이 실제로 얼마나 다른지 평가하기 위하여 집단 내의 변동과 집단 간의 변동을 비교한다. 

* 정의 

세 집단 이상의 집단 평균치의 차이를 검장하는 분석이다. 즉 세 개 이상의 범주로 나뉜 집단간의 양적 변수의 평균 차이를 분석하여 연관성을 찾는 것이다. 

* 분산분석이 필요한 이유 

t-검증에 적용시 세 집단 각각의 차이를 검증하여 절차가 번거롭다. (A-B, B-C, A-C) 오차가 커진다. ($$\alpha = 0.05$$인 경우 3집단 비교시 $$\alpha = 1-(1-0.05)^3 = 0.143)

### 영가설과 대안가설

각 집단의 평균을 $$\mu_1, \mu_2, \mu_3$$이라고 표기하면 가설은 아래와 같다. 

$$H_0 : \mu_1 = \mu_2 = \mu_3$$  
$$H_\alpha$$ : 최소한 하나는 $$\mu_i \neq \mu_j$$

영가설은 세 집단의 평균이 같다는 것이고 대안가설은 세 집단 중 최소한 하나의 평균은 다른 것과 다르다는 것이다. 따라서 대안 가설은 범주형 변수와 양적 변수 사이에 연관이 있다는 것이다.  (어떤 그룹이 다른지를 결정하는 문제는 다음에 다룬다.)

*평균이 같다는 건 변수로서 의미가 없다는 것, 따라서 양적변수에 영향을 못 준다는 것이다.*

### 예시 

샌드위치의 종류에 따라 개미가 다르게 몰려든다. 세 종류의 샌드위치는 베지마이트, 땅콩 버터, 행과 피클을 준비했다. 무작위로 샌드위치 조각을 바닥에 놓고 몇 분 후에 개미의 수를 세었다. 데이터는 아래와 같다. 

![image](https://user-images.githubusercontent.com/67791317/145714026-b5701e71-72d7-46d0-b6ee-d20f54000373.png){: .align-center}

해당 데이터에서 양적 변수는 개미의 수이고 범주형 변수는 샌드위치의 종류(3가지)이다.

요약 통계량

![image](https://user-images.githubusercontent.com/67791317/145719745-ec05a144-23fe-45e0-b1f0-437271b7315e.png){: .align-center}

위 요약 통계량을 보면 샌드위치 유형별로 표본 평균이 다르고 *햄과 피클*의 평균이 상당히 높은 것을 알 수 있다. 하지만 이 차이가 통계적으로 유의한지 확인하여야 한다. 

즉 영가설에 반하는 증거를 확인하려면 영가설이 참일 때 표본은 어떤 것인지 생각해야한다. 영가설은 **모든** 샌드위치의 평균 개미 수가 같다는 것이므로 표본을 모두 함쳐 24개로 이루어진 통합 표본을 만들어야한다. 통합 표본의 평균 $$\bar x = 38.0$$이고 표준편차는 $$s = 13.95$$이다. 

*각 집단의 크기가 같다면 집단별 평균들의 평균이 통합 평균이다. (다르면 따로 통합 표본 평균을 계산해야함)*

## 변동분석 

영가설이 참일 경우 표본은 같은 모집단에서 생성된다. (평균이 같으니까.) 모집단의 평균이 38이라고 가정하자. 평균이 38인 모집단에서 크기가 8인 표본을 추출하면 표본 평균이 30.75, 34.0, 49.25만큼 다를 가능성이 얼마나 될까?

### 변동 분석을 하는 이유 

크게 두가지 이유가 있다. 첫 째, 표본 평균의 변동은 표본 크기뿐만 아니라 모집단의 변동에 의존한다. 둘 째, 모든 그룹의 평균들이 서로 얼마나 떨어져 있는지를 하나의 통계량으로 측정하고 싶다. 이 두 가지 이유로 변동을 분석해야한다. 

*$$*$$변동의 수학적 정의는 통계 자료의 수치들이 크고 작음을 이르는 말이다*  
*$$*$$결국 변동이 작을 수록 영가설이 맞을 확률이 높은것 왜냐면 변동이 작은건 모집단에서 다같이 나올 가능성이 높음*
\
\
![image](https://user-images.githubusercontent.com/67791317/145721140-39f8d7be-9645-419d-8928-99c22265239e.png){: .align-center}

위 그림은 세 그룹을 비교하는 가상 데이터에 의한 상자그림이다. (빨간원은 표본 평균이다.) A와 B에서 평균은 같지만 퍼진 정도(변동)가 다르다. A와 C는 퍼진 정도(변동)은 같지만 그룹 평균은 다르다. 

> 그룹 평균이 같지 않다(같은 모집단에서 나온게 아니다)에 대한 강력한 증거를 제공하는 그래프는 어느 것인가?

데이터 셋 A의 상자그림은 세 그룹 간의 평균 차이에 대한 가장 약한 증거를 보여준다.  
상자 사이에 겹치는 부분(상자그림의 범위가 비슷)이 많아서 모집단 하나에서 3개의 표본이 나올 수 있다. 

데이터 셋 B와 C는 그룹 평균의 차이에 대한 강력한 증거를 보여준다. (서로 범위가 다름) 특히 그룹1의 모든 데이터는 그룹2보다 작다. 

**깨달음**

여러 그룹 간의 평균 차이에 대한 평가는 두 가지 종류의 변동. 즉, '평균이 서로 얼마나 다른지'와 '표본 내의 변동'에 따라 결정된다는 것이다. 그룹의 표본 평균을 아는 것만으로는 충분하지 않다. 표본의 변동이 작으면 B처럼 평균 변동이 작아도 탐지할 수 있다. 하지만 표본의 변동이 크면 데이터 C와 같이 표본 평균 변동도 더 멀리 떨어져 있어야 한다. 

### 변동 분해 

분산분석의 기본 개념은 데이터의 총 변동을 둘 이상으로 나누는 것이다. 평균을 비교할 때 이 중 하나는 그룹간(between) 변동을 반영한다. 집단 평균이 크게 다르면 이 변동이 클 것이다. 다른 하나는 표본 내(within) 변동을 측정한다. 표본의 범위가 넓다면 이 변동이 넓다는 것을 말한다. 

**총 변동 = 그룹 간(between) 변동 + 그룹 내(within) 변동**

각각의 변동은 표본 표준편차와 마찬가지로 **편차의 제곱합**을 사용한다. 계산방법이 존재하지만 컴퓨터를 이용하는 것이 편리하다. 

> 총 변동 

총 제곱합이고 SSTotal로 표기한다. 통합 표본의 평균에서 모든 데이터의 변동을 측정한 값이다. 

> 그룹 간 변동

그룹의 제곱합이며 SSG로 표기한다. 집단의 평균이 얼마나 떨어져 있는지 측정한 값이다. 이것은 집단이 다르다는 것으로 설명할 수 있는 변동이다.

> 그룹 내 변동 

오차 제곱합인데 SSE로 표기한다. 각 그룹 내 변동이 어느 정도인지를 측정한 값이다. 이것은 집단이 다르다는 사실만으로 설명할 수 없는 변동이므로 오차 변동이라 부른다. 

모든 그룹 평균이 정확히 같다면, 그룹 간 변동(SSG)는 0이 될 것이다. 만약 개미들의 수 (데이터 값들)이 모두 같다면, 그룹 내 변동(SSE)는 0이 될 것이다. 

**SSTotal = SSG + SSE**

*총변동이 작다는 것은 집단의 평균 차이가 없다는 것이다. 그룹간, 그룹내 변동이 작다는 건 같은 모집단에서 추출되었을 확률이 높다는 것이고 결국 평균이 같다는 것과 동일하다.*

## F 통계량 

분산분석을 하는 목표는 데이터가 집단 간에 평균 차이가 있다는 증거를 제공하는지 검증하는 것이다. 그룹 간 변동(SSG)는 그룹 평균이 얼마나 다른지 보여주는 좋은 측도이지만, 그룹 내 변동(SSE)와 균형이 맞아야한다. (그룹 간 평균이 멀어도 데이터의 범위가 겹치면 판단하기 어려움) 샌드위치 데이터에서 SSG는 세 개의 평균 사이의 변동이지만, SSE는 24개 데이터 모두에 대한 변동(데이터들의 범위는 결국 통합 표본의 범위와 비슷하니까 데이터 모두에 대한 변동이다.)이므로 이 **둘을 직접 비교할 수는 없다**. 비교하기 위해선 **자유도**가 필요하다. 

총 데이터 수가 n이고 그룹 수가 k이면 

총 변동(SSTatal)의 자유도 = $$n-1$$
그룹 간 변동(SSG)의 자유도 = $$k-1$$
오차 제곱합(SSE)의 자유도 = $$n-k$$ (각 그룹에서 평균을 계산할 때 자유도 1을 상실하기 때문)

자유도는 제곱합과 같은 방식으로 합산된다. 

SSTatal 자유도(n-1) = SSG 자유도(k-1) + SSE 자유도(n-k)

제곱합을 비교 가능한 측도로 만들기 위해 제곱합을 자유도로 나눈다. 이 값을 **평균제곱**이라 부른다.

$$
평균제곱 = \frac{제곱합}{자유도}
$$

그룹 평균제곱(MSG, Mean Square for Groups)과 오차 평균제곱(MSE, Mean Square for Error)는 다음과 같이 계산한다. 

$$
MSG = \frac{SSG}{k-1}, MSE = \frac{SSE}{n-k}
$$

이제 여러 평균의 차이를 검증하기 위한 통계량을 정의할 수 있다. 영가설이 참(모든 집단의 평균이 같다)이라면, 두 평균제곱인 MSG와 MSE는 대략 같은 크기가 된다. 대안가설이 참이라면 MSG가 MSE에 비해 더 크게 나온다. 표본 평균의 변동이 그룹 내 변동보다 더 크기 때문이다. 두 변동의 추정치를 비교하는 F-통계량은 다음이다. 

$$
F = \frac{MSG}{MSE}
$$

*F통계량은 클 수록 좋겠네, 왜냐면 MSG가 MSE보다 커야 대안가설이 참일테니까*

## F-분포

다음 두 조건이 만족되면 F-분포를 사용하여 p-값을 구할 수 있다. 

> 정규분포 : 각 모집단의 데이터 분포가 정규분포와 근사해야한다. 표본크기가 작다면 이상점과 비대칭성을 유의한다. 표본크기가 크다면 중심극한정리로 정규분포와 근사하다고 생각한다. 정규분포와 근사하지 않다면 F-분포를 사용할 수 없다. 

> 등분산 : 각 그룹의 변동은 거의 같아야 한다. 일반적으로 평균이 커지면 변동도 커지는 경향이 있다. 이런 경우는 등분산 가정이 성립하지 않을 수 있다. 대략 한 그룹의 표본 표준편차가 다른 그룹의 표본 표준편차의 2배 이상이면 문제가 된다. 

위 두 조건이 충족되면 영가설이 참일 때의 F-통계량은 F-분포를 따른다. F-분포는 두 개의 평균제곱의 비율에 대한 분포이므로 자유도를 두 개 가진다. 하나는 분자(MSG 자유도), 다른 하나는 분모(MSE 자유도)에 대한 것이다. 표기는 $$F_{k-1,n-k}$$로 한다. 아래는 $$F_{k-1,n-k}$$ 분포의 그림이다

<img src = "https://user-images.githubusercontent.com/67791317/145829785-431efe6f-dbf5-43d9-8e6c-7e8f9ccf2de4.png" :  width="600" height="300">

위와 같은 F-분포를 활용하여 F-통계량 보다 더 큰쪽의 면적을 찾으면 p값을 구할 수 있다. p값을 통해 영가설의 채택 여부를 검증한다. 

## 요약 

k개 그룹의 평균 차이를 검증할 때 가설은 다음과 같다. 

$$H_0 : \mu_1 = \mu_2 = \cdot \cdot \cdot = \mu_k$$  
$$H_\alpha :$$ 최소한 하나는 $$\mu_i = \mu_j$$

변동을 분해하는 분산분석 표를 만든다. 

![image](https://user-images.githubusercontent.com/67791317/145835354-c31ef3be-fd65-4d09-a50c-a3f0912f2c76.png){: .align-center}

F-분포를 사용하여 p값을 구하려면 다음 두 조건을 성립해야한다.

- 표본 크기가 크거나(각 그룹의 표본 크기가 30 이상) 대략 정규분포를 근사해야한다.  
- 모든 그룹의 변동이 비슷해야한다. (평균이 너무 커지거나, 한 그룹의 표본 표준편차가 다른 그룹의 표본 표준편차보다 2배 이상이면 문제가 된다.)

구한 F-통계량을 자유도에 따른 F-분포에 따라 p값을 구하여 가설 검증을 한다. 

대안 가설이 채택되면 그룹간의 평균 차이가 존재한다는 증거를 갖게된다. 이는 양적변수에게 범주형 변수가 연관이 있다는 것이다. 왜냐면 서로 연관이 있기 때문에 해당 범주형 변수 때문에 평균차이가 존재하는 것이니까. 